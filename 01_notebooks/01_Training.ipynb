{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# 01 — YOLOv8 Training\n",
    "## Heavy Vehicle Detection During Peak-Hour Ban Periods\n",
    "\n",
    "**Module:** MAICEN 1125 · M4 · U3 · FMP Group Assignment\n",
    "\n",
    "This notebook covers:\n",
    "- Environment setup & GPU check\n",
    "- Dataset download from GitHub (no API key required)\n",
    "- YOLOv8n model training (50 epochs full / 5 epochs verify)\n",
    "- Training metrics + curves\n",
    "- Saving best weights\n",
    "\n",
    "> ▶ **Runtime → Change runtime type → T4 GPU** before running.\n",
    "\n",
    "After training, move to **`02_Inference.ipynb`** for validation + new-image predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1-md",
   "metadata": {},
   "source": [
    "## Cell 1 — Install Dependencies & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics --quiet\n",
    "\n",
    "import torch\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"Ultralytics : {ultralytics.__version__}\")\n",
    "print(f\"PyTorch     : {torch.__version__}\")\n",
    "print(f\"CUDA        : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU         : {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Save pip freeze snippet for reproducibility\n",
    "!pip freeze | grep -E 'ultralytics|torch' > /content/pip_freeze_snippet.txt\n",
    "print(\"\\npip freeze snippet → /content/pip_freeze_snippet.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2-md",
   "metadata": {},
   "source": [
    "## Cell 2 — Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── CONFIGURATION ────────────────────────────────────────────────────────────\n",
    "VERIFY_ONLY   = False          # True = 5-epoch quick check; False = full 50-epoch run\n",
    "MODEL_VARIANT = 'yolov8n.pt'  # yolov8n (nano) | yolov8s (small)\n",
    "EPOCHS        = 5 if VERIFY_ONLY else 50\n",
    "BATCH         = 16\n",
    "IMGSZ         = 640\n",
    "PROJECT_NAME  = 'heavy_vehicle_detection'\n",
    "RUN_NAME      = f'yolov8n_{EPOCHS}ep'\n",
    "\n",
    "# GitHub repository\n",
    "GITHUB_REPO   = \"https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods.git\"\n",
    "REPO_NAME     = \"Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods\"\n",
    "DATASET_DIR   = f\"/content/{REPO_NAME}/images dataset\"\n",
    "\n",
    "print(f\"Mode      : {'VERIFY (5 ep)' if VERIFY_ONLY else 'FULL TRAINING (50 ep)'}\")\n",
    "print(f\"Model     : {MODEL_VARIANT}\")\n",
    "print(f\"Epochs    : {EPOCHS} | Batch: {BATCH} | Img: {IMGSZ}px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3-md",
   "metadata": {},
   "source": [
    "## Cell 3 — Clone Dataset from GitHub\n",
    "\n",
    "No API key required. The dataset lives at `images dataset/` inside the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Clone the repository (skip if already cloned)\n",
    "if not os.path.exists(f\"/content/{REPO_NAME}\"):\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone --depth 1 \"{GITHUB_REPO}\" \"/content/{REPO_NAME}\"\n",
    "else:\n",
    "    print(\"Repository already cloned — pulling latest...\")\n",
    "    !git -C \"/content/{REPO_NAME}\" pull\n",
    "\n",
    "print(f\"\\nDataset folder: {DATASET_DIR}\")\n",
    "print(\"Contents:\", os.listdir(DATASET_DIR))\n",
    "\n",
    "# ── Locate or create data.yaml ──────────────────────────────────────────────\n",
    "DATA_YAML = os.path.join(DATASET_DIR, \"data.yaml\")\n",
    "\n",
    "if not os.path.exists(DATA_YAML):\n",
    "    print(\"data.yaml not found — generating from folder structure...\")\n",
    "    yaml_content = {\n",
    "        \"train\": os.path.join(DATASET_DIR, \"train\", \"images\"),\n",
    "        \"val\":   os.path.join(DATASET_DIR, \"valid\", \"images\"),\n",
    "        \"test\":  os.path.join(DATASET_DIR, \"test\",  \"images\"),\n",
    "        \"nc\":    3,\n",
    "        \"names\": [\"bus\", \"car\", \"truck\"]\n",
    "    }\n",
    "    with open(DATA_YAML, \"w\") as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    print(f\"data.yaml created at: {DATA_YAML}\")\n",
    "else:\n",
    "    print(f\"data.yaml found at: {DATA_YAML}\")\n",
    "\n",
    "# Confirm classes\n",
    "with open(DATA_YAML) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "print(f\"Classes ({cfg['nc']}): {cfg['names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4-md",
   "metadata": {},
   "source": [
    "## Cell 4 — Dataset Sanity Check (Image Count & Class Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import Counter\n",
    "\n",
    "# Count images per split\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    img_dir = os.path.join(DATASET_DIR, split, 'images')\n",
    "    if os.path.isdir(img_dir):\n",
    "        n = len(os.listdir(img_dir))\n",
    "        print(f\"{split:5s}: {n} images\")\n",
    "    else:\n",
    "        print(f\"{split:5s}: folder not found at {img_dir}\")\n",
    "\n",
    "# Count class instances in training labels\n",
    "label_dir = os.path.join(DATASET_DIR, 'train', 'labels')\n",
    "class_counts = Counter()\n",
    "if os.path.isdir(label_dir):\n",
    "    for lf in glob.glob(os.path.join(label_dir, '*.txt')):\n",
    "        with open(lf) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    cls_id = int(parts[0])\n",
    "                    class_counts[cfg['names'][cls_id]] += 1\n",
    "\n",
    "print(\"\\nTraining label distribution:\")\n",
    "for cls, cnt in sorted(class_counts.items()):\n",
    "    print(f\"  {cls:8s}: {cnt} instances\")\n",
    "\n",
    "# Bar chart\n",
    "if class_counts:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(class_counts.keys(), class_counts.values(),\n",
    "            color=['#2196F3', '#4CAF50', '#FF5722'])\n",
    "    plt.title('Training Instance Count per Class')\n",
    "    plt.ylabel('Instances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/class_distribution.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Sample grid of training images\n",
    "train_img_dir = os.path.join(DATASET_DIR, 'train', 'images')\n",
    "if os.path.isdir(train_img_dir):\n",
    "    all_imgs = os.listdir(train_img_dir)\n",
    "    samples  = random.sample(all_imgs, min(6, len(all_imgs)))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    for ax, fn in zip(axes.flatten(), samples):\n",
    "        ax.imshow(mpimg.imread(os.path.join(train_img_dir, fn)))\n",
    "        ax.set_title(fn[:22], fontsize=8)\n",
    "        ax.axis('off')\n",
    "    plt.suptitle('Sample Training Images', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/sample_training_images.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5-md",
   "metadata": {},
   "source": [
    "## Cell 5 — Train YOLOv8\n",
    "\n",
    "| Mode | Expected runtime (T4 GPU) |\n",
    "|------|---------------------------|\n",
    "| Full (50 ep) | ~25–35 min |\n",
    "| Verify (5 ep) | ~3–5 min |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(MODEL_VARIANT)\n",
    "\n",
    "results = model.train(\n",
    "    data     = DATA_YAML,\n",
    "    epochs   = EPOCHS,\n",
    "    batch    = BATCH,\n",
    "    imgsz    = IMGSZ,\n",
    "    project  = f'/content/{PROJECT_NAME}',\n",
    "    name     = RUN_NAME,\n",
    "    patience = 10,\n",
    "    save     = True,\n",
    "    plots    = True,\n",
    "    device   = 0 if torch.cuda.is_available() else 'cpu',\n",
    "    exist_ok = True,\n",
    "    verbose  = True\n",
    ")\n",
    "\n",
    "WEIGHTS = f'/content/{PROJECT_NAME}/{RUN_NAME}/weights/best.pt'\n",
    "print(f\"\\n✅ Training complete. Best weights → {WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6-md",
   "metadata": {},
   "source": [
    "## Cell 6 — Validation Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "best_model = YOLO(WEIGHTS)\n",
    "metrics    = best_model.val(\n",
    "    data   = DATA_YAML,\n",
    "    imgsz  = IMGSZ,\n",
    "    device = 0 if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*52)\n",
    "print(\"  VALIDATION METRICS\")\n",
    "print(\"=\"*52)\n",
    "print(f\"  mAP@0.5        : {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95   : {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision (all): {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall (all)   : {metrics.box.mr:.4f}\")\n",
    "print(\"=\"*52)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Class'     : cfg['names'],\n",
    "    'Precision' : metrics.box.p,\n",
    "    'Recall'    : metrics.box.r,\n",
    "    'mAP@0.5'   : metrics.box.ap50,\n",
    "    'mAP@0.5:95': metrics.box.ap\n",
    "})\n",
    "print(\"\\nPer-class:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7-md",
   "metadata": {},
   "source": [
    "## Cell 7 — Training Curves (results.png, Confusion Matrix, PR Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = f'/content/{PROJECT_NAME}/{RUN_NAME}/'\n",
    "\n",
    "for fname, title in [\n",
    "    ('results.png',           'Training Curves (loss / P / R / mAP)'),\n",
    "    ('confusion_matrix.png',  'Confusion Matrix'),\n",
    "    ('PR_curve.png',          'Precision-Recall Curve'),\n",
    "    ('F1_curve.png',          'F1 Curve'),\n",
    "]:\n",
    "    path = os.path.join(run_dir, fname)\n",
    "    if os.path.exists(path):\n",
    "        img = mpimg.imread(path)\n",
    "        w   = 14 if fname == 'results.png' else 8\n",
    "        plt.figure(figsize=(w, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"Shown: {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8-md",
   "metadata": {},
   "source": [
    "## Cell 8 — Save Weights Path for Inference Notebook\n",
    "\n",
    "Copy the printed path and paste it into `02_Inference.ipynb` → Cell 2 as `WEIGHTS_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  WEIGHTS PATH (copy into 02_Inference.ipynb)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  {WEIGHTS}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Zip weights + curves for download / GitHub Release\n",
    "os.makedirs('/content/training_outputs/curves', exist_ok=True)\n",
    "shutil.copy(WEIGHTS, '/content/training_outputs/')\n",
    "\n",
    "for fname in ['results.png', 'confusion_matrix.png', 'PR_curve.png', 'F1_curve.png']:\n",
    "    src = os.path.join(run_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, '/content/training_outputs/curves/')\n",
    "\n",
    "shutil.make_archive('/content/training_outputs', 'zip', '/content/training_outputs')\n",
    "print(\"\\nOutputs zipped → /content/training_outputs.zip\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('/content/training_outputs.zip')\n",
    "except ImportError:\n",
    "    print(\"(Not in Colab — download manually)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "---\n",
    "## Reproducibility Log\n",
    "\n",
    "Fill in after a successful run and copy to the README:\n",
    "\n",
    "| Field | Value |\n",
    "|-------|-------|\n",
    "| Date/time (UTC) | _(fill in)_ |\n",
    "| GPU | _(e.g. T4 16 GB)_ |\n",
    "| Ultralytics version | _(from pip_freeze_snippet.txt)_ |\n",
    "| Runtime (50 ep) | _(e.g. 28 min)_ |\n",
    "| mAP@0.5 achieved | _(fill in)_ |\n",
    "\n",
    "---\n",
    "*MAICEN 1125 M4 U3 FMP — February 2026*"
   ]
  }
 ]
}
