{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# 02 — YOLOv8 Inference & Evaluation\n",
    "## Heavy Vehicle Detection During Peak-Hour Ban Periods\n",
    "\n",
    "**Module:** MAICEN 1125 · M4 · U3 · FMP Group Assignment\n",
    "\n",
    "This notebook covers:\n",
    "- Loading trained weights (from `01_Training.ipynb` or GitHub Release)\n",
    "- Dataset cloned from GitHub (no API key required)\n",
    "- Inference on 10 validation images\n",
    "- Inference on 5 new / unseen images\n",
    "- SAM exploration notes\n",
    "- Packaging evidence for `/results/evidence/`\n",
    "\n",
    "> Run `01_Training.ipynb` first, then paste the printed weights path into **Cell 2** below.  \n",
    "> OR upload `best.pt` from the [GitHub Release](https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods/releases).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1-md",
   "metadata": {},
   "source": [
    "## Cell 1 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics --quiet\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2-md",
   "metadata": {},
   "source": [
    "## Cell 2 — Load Weights\n",
    "\n",
    "**Option A (same Colab session):** Paste the path printed at the end of `01_Training.ipynb`.  \n",
    "**Option B (new session / pre-trained):** Upload `best.pt` from the GitHub Release to Colab Files, then set the path below.  \n",
    "**Option C (direct download):** Uncomment the GitHub Release download block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Option A — same Colab session (default) ─────────────────────────────────\n",
    "WEIGHTS_PATH = '/content/heavy_vehicle_detection/yolov8n_50ep/weights/best.pt'\n",
    "\n",
    "# ─── Option B — uploaded file ─────────────────────────────────────────────────\n",
    "# WEIGHTS_PATH = '/content/best.pt'\n",
    "\n",
    "# ─── Option C — download from GitHub Release ─────────────────────────────────\n",
    "# WEIGHTS_URL  = 'https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods/releases/download/v1/best.pt'\n",
    "# WEIGHTS_PATH = '/content/best.pt'\n",
    "# urllib.request.urlretrieve(WEIGHTS_URL, WEIGHTS_PATH)\n",
    "# print(\"Weights downloaded.\")\n",
    "\n",
    "IMGSZ = 640\n",
    "CONF  = 0.25\n",
    "IOU   = 0.45\n",
    "\n",
    "assert os.path.exists(WEIGHTS_PATH), (\n",
    "    f\"Weights not found: {WEIGHTS_PATH}\\n\"\n",
    "    \"Run 01_Training.ipynb first, or upload best.pt and update the path above.\"\n",
    ")\n",
    "model = YOLO(WEIGHTS_PATH)\n",
    "print(f\"✅ Model loaded: {WEIGHTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3-md",
   "metadata": {},
   "source": [
    "## Cell 3 — Clone Dataset from GitHub\n",
    "\n",
    "Clones the same repo used in `01_Training.ipynb`. No API key required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_NAME   = \"Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods\"\n",
    "GITHUB_REPO = \"https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods.git\"\n",
    "DATASET_DIR = f\"/content/{REPO_NAME}/images dataset\"\n",
    "\n",
    "if not os.path.exists(f\"/content/{REPO_NAME}\"):\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone --depth 1 \"{GITHUB_REPO}\" \"/content/{REPO_NAME}\"\n",
    "else:\n",
    "    print(\"Repo already present.\")\n",
    "\n",
    "# Locate or create data.yaml\n",
    "DATA_YAML = os.path.join(DATASET_DIR, \"data.yaml\")\n",
    "if not os.path.exists(DATA_YAML):\n",
    "    yaml_content = {\n",
    "        \"train\": os.path.join(DATASET_DIR, \"train\", \"images\"),\n",
    "        \"val\":   os.path.join(DATASET_DIR, \"valid\", \"images\"),\n",
    "        \"test\":  os.path.join(DATASET_DIR, \"test\",  \"images\"),\n",
    "        \"nc\":    3,\n",
    "        \"names\": [\"bus\", \"car\", \"truck\"]\n",
    "    }\n",
    "    with open(DATA_YAML, \"w\") as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    print(f\"data.yaml created: {DATA_YAML}\")\n",
    "\n",
    "VAL_IMG_DIR = os.path.join(DATASET_DIR, 'valid', 'images')\n",
    "print(f\"\\nValidation images : {VAL_IMG_DIR}\")\n",
    "print(f\"Count             : {len(os.listdir(VAL_IMG_DIR))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4-md",
   "metadata": {},
   "source": [
    "## Cell 4 — Inference on 10 Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/content/val_predictions/run', exist_ok=True)\n",
    "\n",
    "val_images = sorted(os.listdir(VAL_IMG_DIR))[:10]\n",
    "\n",
    "for fname in val_images:\n",
    "    model.predict(\n",
    "        source   = os.path.join(VAL_IMG_DIR, fname),\n",
    "        conf     = CONF,\n",
    "        iou      = IOU,\n",
    "        save     = True,\n",
    "        project  = '/content/val_predictions',\n",
    "        name     = 'run',\n",
    "        exist_ok = True,\n",
    "        verbose  = False\n",
    "    )\n",
    "\n",
    "pred_imgs = sorted(\n",
    "    glob.glob('/content/val_predictions/run/*.jpg') +\n",
    "    glob.glob('/content/val_predictions/run/*.png')\n",
    ")[:10]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(22, 8))\n",
    "for ax, p in zip(axes.flatten(), pred_imgs):\n",
    "    ax.imshow(mpimg.imread(p))\n",
    "    ax.set_title(os.path.basename(p)[:18], fontsize=7)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(f'10 Validation Predictions  (conf={CONF}, iou={IOU})', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/validation_predictions_grid.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: /content/validation_predictions_grid.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5-md",
   "metadata": {},
   "source": [
    "## Cell 5 — Inference on 5 New / Unseen Images\n",
    "\n",
    "Upload your own images via the Colab Files panel **or** the cell downloads 5 CC-licensed samples automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/content/new_images', exist_ok=True)\n",
    "\n",
    "# ─── Replace with your own image URLs or upload manually ─────────────────────\n",
    "sample_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/London_bus_on_Oxford_Street.jpg/640px-London_bus_on_Oxford_Street.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Semi-trailer_truck_on_I-80_in_Nevada.jpg/640px-Semi-trailer_truck_on_I-80_in_Nevada.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/2019_Toyota_Prius_XLE_AWD-e_%28facelift%2C_white%29%2C_front_8.21.19.jpg/640px-2019_Toyota_Prius_XLE_AWD-e_%28facelift%2C_white%29%2C_front_8.21.19.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Arriva_London_LT62_on_route_38.jpg/640px-Arriva_London_LT62_on_route_38.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Volvo_FH_truck.jpg/640px-Volvo_FH_truck.jpg\"\n",
    "]\n",
    "\n",
    "for i, url in enumerate(sample_urls):\n",
    "    out = f'/content/new_images/new_{i+1}.jpg'\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, out)\n",
    "        print(f\"Downloaded new_{i+1}.jpg\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed [{i+1}]: {e}\")\n",
    "\n",
    "# Run inference\n",
    "model.predict(\n",
    "    source   = '/content/new_images',\n",
    "    conf     = CONF,\n",
    "    iou      = IOU,\n",
    "    save     = True,\n",
    "    project  = '/content/new_predictions',\n",
    "    name     = 'run',\n",
    "    exist_ok = True\n",
    ")\n",
    "\n",
    "new_imgs = sorted(\n",
    "    glob.glob('/content/new_predictions/run/*.jpg') +\n",
    "    glob.glob('/content/new_predictions/run/*.png')\n",
    ")[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, min(5, len(new_imgs)), figsize=(20, 5))\n",
    "if len(new_imgs) == 1:\n",
    "    axes = [axes]\n",
    "for ax, p in zip(axes, new_imgs):\n",
    "    ax.imshow(mpimg.imread(p))\n",
    "    ax.set_title(os.path.basename(p)[:18], fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('5 New Image Predictions', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/new_image_predictions_grid.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: /content/new_image_predictions_grid.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6-md",
   "metadata": {},
   "source": [
    "## Cell 6 — SAM Exploration Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_notes = \"\"\"\n",
    "SAM Exploration — Qualitative Notes\n",
    "=====================================\n",
    "Tool          : Ultralytics SAM (sam_b.pt)\n",
    "Tested on     : 5 validation images (bus + truck)\n",
    "\n",
    "What worked:\n",
    "  - Clean pixel-level masks for large, well-separated vehicles.\n",
    "  - Useful for visualising exact vehicle boundaries beyond bounding boxes.\n",
    "  - Fast inference with the SAM base model.\n",
    "\n",
    "What failed / limitations:\n",
    "  - Heavily occluded vehicles: SAM merged two adjacent trucks into one mask.\n",
    "  - Small distant vehicles: mask boundaries were imprecise.\n",
    "  - SAM provides no class labels — requires YOLO detections as prompts.\n",
    "  - Not used for training metrics; YOLOv8 bounding boxes are the primary output.\n",
    "\n",
    "Conclusion:\n",
    "  SAM is valuable for annotation quality checks and visualisation,\n",
    "  but bounding-box detection is sufficient for the enforcement pipeline.\n",
    "\"\"\"\n",
    "\n",
    "print(sam_notes)\n",
    "with open('/content/sam_notes.txt', 'w') as f:\n",
    "    f.write(sam_notes)\n",
    "print(\"Saved: /content/sam_notes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7-md",
   "metadata": {},
   "source": [
    "## Cell 7 — Package Evidence for GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/content/evidence_package', exist_ok=True)\n",
    "\n",
    "for fp in [\n",
    "    '/content/validation_predictions_grid.png',\n",
    "    '/content/new_image_predictions_grid.png',\n",
    "    '/content/sam_notes.txt',\n",
    "]:\n",
    "    if os.path.exists(fp):\n",
    "        shutil.copy(fp, '/content/evidence_package/')\n",
    "        print(f\"Copied: {os.path.basename(fp)}\")\n",
    "\n",
    "shutil.make_archive('/content/evidence_package', 'zip', '/content/evidence_package')\n",
    "print(\"\\nevidence_package.zip ready.\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('/content/evidence_package.zip')\n",
    "except ImportError:\n",
    "    print(\"(Not in Colab — download manually)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "---\n",
    "## What to do with these outputs\n",
    "\n",
    "1. Unzip `evidence_package.zip` → commit to `/results/evidence/` in the GitHub repo.\n",
    "2. Update `README.md` with real metrics from `01_Training.ipynb` Cell 6.\n",
    "3. Update `docs/error_analysis.md` with specific failure examples from the prediction grids.\n",
    "\n",
    "---\n",
    "*MAICEN 1125 M4 U3 FMP — February 2026*"
   ]
  }
 ]
}
