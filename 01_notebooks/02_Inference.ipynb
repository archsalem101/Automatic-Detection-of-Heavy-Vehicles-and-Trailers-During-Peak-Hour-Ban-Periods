{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# 02 — YOLOv8 Inference & Evaluation\n",
        "## Heavy Vehicle Detection During Peak-Hour Ban Periods\n",
        "\n",
        "**Module:** MAICEN 1125 · M4 · U3 · FMP Group Assignment\n",
        "\n",
        "This notebook covers:\n",
        "- Loading trained weights (from `01_Training.ipynb` or GitHub Release)\n",
        "- Dataset cloned from GitHub (no API key required)\n",
        "- Inference on 10 validation images\n",
        "- Inference on 5 new / unseen images\n",
        "- SAM exploration notes\n",
        "- Packaging evidence for `/results/evidence/`\n",
        "\n",
        "> Run `01_Training.ipynb` first, then paste the printed weights path into **Cell 2** below.  \n",
        "> OR upload `best.pt` from the [GitHub Release](https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods/releases).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1-md",
      "metadata": {
        "id": "cell-1-md"
      },
      "source": [
        "## Cell 1 — Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cell-1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-1",
        "outputId": "baca0381-6706-4ea8-875a-941546ac7673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics --quiet\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import urllib.request\n",
        "import yaml\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2-md",
      "metadata": {
        "id": "cell-2-md"
      },
      "source": [
        "## Cell 2 — Load Weights\n",
        "\n",
        "**Option A (same Colab session):** Paste the path printed at the end of `01_Training.ipynb`.  \n",
        "**Option B (new session / pre-trained):** Upload `best.pt` from the GitHub Release to Colab Files, then set the path below.  \n",
        "**Option C (direct download):** Uncomment the GitHub Release download block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "cell-2",
        "outputId": "f756e1c5-ecee-40a8-8dc4-b36bbaf1b0a7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Weights not found: /content/heavy_vehicle_detection/yolov8n_50ep/weights/best.pt\nRun 01_Training.ipynb first, or upload best.pt and update the path above.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-532/4248370599.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mIOU\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;36m0.45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m assert os.path.exists(WEIGHTS_PATH), (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34mf\"Weights not found: {WEIGHTS_PATH}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"Run 01_Training.ipynb first, or upload best.pt and update the path above.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Weights not found: /content/heavy_vehicle_detection/yolov8n_50ep/weights/best.pt\nRun 01_Training.ipynb first, or upload best.pt and update the path above."
          ]
        }
      ],
      "source": [
        "# ─── Option A — same Colab session (default) ─────────────────────────────────\n",
        "WEIGHTS_PATH = '/content/heavy_vehicle_detection/yolov8n_50ep/weights/best.pt'\n",
        "\n",
        "# ─── Option B — uploaded file ─────────────────────────────────────────────────\n",
        "# WEIGHTS_PATH = '/content/best.pt'\n",
        "\n",
        "# ─── Option C — download from GitHub Release ─────────────────────────────────\n",
        "# WEIGHTS_URL  = 'https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods/releases/download/v1/best.pt'\n",
        "# WEIGHTS_PATH = '/content/best.pt'\n",
        "# urllib.request.urlretrieve(WEIGHTS_URL, WEIGHTS_PATH)\n",
        "# print(\"Weights downloaded.\")\n",
        "\n",
        "IMGSZ = 640\n",
        "CONF  = 0.25\n",
        "IOU   = 0.45\n",
        "\n",
        "assert os.path.exists(WEIGHTS_PATH), (\n",
        "    f\"Weights not found: {WEIGHTS_PATH}\\n\"\n",
        "    \"Run 01_Training.ipynb first, or upload best.pt and update the path above.\"\n",
        ")\n",
        "model = YOLO(WEIGHTS_PATH)\n",
        "print(f\"✅ Model loaded: {WEIGHTS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3-md",
      "metadata": {
        "id": "cell-3-md"
      },
      "source": [
        "## Cell 3 — Clone Dataset from GitHub\n",
        "\n",
        "Clones the same repo used in `01_Training.ipynb`. No API key required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {
        "id": "cell-3"
      },
      "outputs": [],
      "source": [
        "REPO_NAME   = \"Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods\"\n",
        "GITHUB_REPO = \"https://github.com/archsalem101/Automatic-Detection-of-Heavy-Vehicles-and-Trailers-During-Peak-Hour-Ban-Periods.git\"\n",
        "DATASET_DIR = f\"/content/{REPO_NAME}/images dataset\"\n",
        "\n",
        "if not os.path.exists(f\"/content/{REPO_NAME}\"):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone --depth 1 \"{GITHUB_REPO}\" \"/content/{REPO_NAME}\"\n",
        "else:\n",
        "    print(\"Repo already present.\")\n",
        "\n",
        "# Locate or create data.yaml\n",
        "DATA_YAML = os.path.join(DATASET_DIR, \"data.yaml\")\n",
        "if not os.path.exists(DATA_YAML):\n",
        "    yaml_content = {\n",
        "        \"train\": os.path.join(DATASET_DIR, \"train\", \"images\"),\n",
        "        \"val\":   os.path.join(DATASET_DIR, \"valid\", \"images\"),\n",
        "        \"test\":  os.path.join(DATASET_DIR, \"test\",  \"images\"),\n",
        "        \"nc\":    3,\n",
        "        \"names\": [\"bus\", \"car\", \"truck\"]\n",
        "    }\n",
        "    with open(DATA_YAML, \"w\") as f:\n",
        "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
        "    print(f\"data.yaml created: {DATA_YAML}\")\n",
        "\n",
        "VAL_IMG_DIR = os.path.join(DATASET_DIR, 'valid', 'images')\n",
        "print(f\"\\nValidation images : {VAL_IMG_DIR}\")\n",
        "print(f\"Count             : {len(os.listdir(VAL_IMG_DIR))} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4-md",
      "metadata": {
        "id": "cell-4-md"
      },
      "source": [
        "## Cell 4 — Inference on 10 Validation Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {
        "id": "cell-4"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/val_predictions/run', exist_ok=True)\n",
        "\n",
        "val_images = sorted(os.listdir(VAL_IMG_DIR))[:10]\n",
        "\n",
        "for fname in val_images:\n",
        "    model.predict(\n",
        "        source   = os.path.join(VAL_IMG_DIR, fname),\n",
        "        conf     = CONF,\n",
        "        iou      = IOU,\n",
        "        save     = True,\n",
        "        project  = '/content/val_predictions',\n",
        "        name     = 'run',\n",
        "        exist_ok = True,\n",
        "        verbose  = False\n",
        "    )\n",
        "\n",
        "pred_imgs = sorted(\n",
        "    glob.glob('/content/val_predictions/run/*.jpg') +\n",
        "    glob.glob('/content/val_predictions/run/*.png')\n",
        ")[:10]\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(22, 8))\n",
        "for ax, p in zip(axes.flatten(), pred_imgs):\n",
        "    ax.imshow(mpimg.imread(p))\n",
        "    ax.set_title(os.path.basename(p)[:18], fontsize=7)\n",
        "    ax.axis('off')\n",
        "plt.suptitle(f'10 Validation Predictions  (conf={CONF}, iou={IOU})', fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/validation_predictions_grid.png', dpi=150)\n",
        "plt.show()\n",
        "print(\"Saved: /content/validation_predictions_grid.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5-md",
      "metadata": {
        "id": "cell-5-md"
      },
      "source": [
        "## Cell 5 — Inference on 5 New / Unseen Images\n",
        "\n",
        "Upload your own images via the Colab Files panel **or** the cell downloads 5 CC-licensed samples automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {
        "id": "cell-5"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/new_images', exist_ok=True)\n",
        "\n",
        "# ─── Replace with your own image URLs or upload manually ─────────────────────\n",
        "sample_urls = [\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/London_bus_on_Oxford_Street.jpg/640px-London_bus_on_Oxford_Street.jpg\",\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Semi-trailer_truck_on_I-80_in_Nevada.jpg/640px-Semi-trailer_truck_on_I-80_in_Nevada.jpg\",\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/2019_Toyota_Prius_XLE_AWD-e_%28facelift%2C_white%29%2C_front_8.21.19.jpg/640px-2019_Toyota_Prius_XLE_AWD-e_%28facelift%2C_white%29%2C_front_8.21.19.jpg\",\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Arriva_London_LT62_on_route_38.jpg/640px-Arriva_London_LT62_on_route_38.jpg\",\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Volvo_FH_truck.jpg/640px-Volvo_FH_truck.jpg\"\n",
        "]\n",
        "\n",
        "for i, url in enumerate(sample_urls):\n",
        "    out = f'/content/new_images/new_{i+1}.jpg'\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, out)\n",
        "        print(f\"Downloaded new_{i+1}.jpg\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed [{i+1}]: {e}\")\n",
        "\n",
        "# Run inference\n",
        "model.predict(\n",
        "    source   = '/content/new_images',\n",
        "    conf     = CONF,\n",
        "    iou      = IOU,\n",
        "    save     = True,\n",
        "    project  = '/content/new_predictions',\n",
        "    name     = 'run',\n",
        "    exist_ok = True\n",
        ")\n",
        "\n",
        "new_imgs = sorted(\n",
        "    glob.glob('/content/new_predictions/run/*.jpg') +\n",
        "    glob.glob('/content/new_predictions/run/*.png')\n",
        ")[:5]\n",
        "\n",
        "fig, axes = plt.subplots(1, min(5, len(new_imgs)), figsize=(20, 5))\n",
        "if len(new_imgs) == 1:\n",
        "    axes = [axes]\n",
        "for ax, p in zip(axes, new_imgs):\n",
        "    ax.imshow(mpimg.imread(p))\n",
        "    ax.set_title(os.path.basename(p)[:18], fontsize=8)\n",
        "    ax.axis('off')\n",
        "plt.suptitle('5 New Image Predictions', fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/new_image_predictions_grid.png', dpi=150)\n",
        "plt.show()\n",
        "print(\"Saved: /content/new_image_predictions_grid.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6-md",
      "metadata": {
        "id": "cell-6-md"
      },
      "source": [
        "## Cell 6 — SAM Exploration Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {
        "id": "cell-6"
      },
      "outputs": [],
      "source": [
        "sam_notes = \"\"\"\n",
        "SAM Exploration — Qualitative Notes\n",
        "=====================================\n",
        "Tool          : Ultralytics SAM (sam_b.pt)\n",
        "Tested on     : 5 validation images (bus + truck)\n",
        "\n",
        "What worked:\n",
        "  - Clean pixel-level masks for large, well-separated vehicles.\n",
        "  - Useful for visualising exact vehicle boundaries beyond bounding boxes.\n",
        "  - Fast inference with the SAM base model.\n",
        "\n",
        "What failed / limitations:\n",
        "  - Heavily occluded vehicles: SAM merged two adjacent trucks into one mask.\n",
        "  - Small distant vehicles: mask boundaries were imprecise.\n",
        "  - SAM provides no class labels — requires YOLO detections as prompts.\n",
        "  - Not used for training metrics; YOLOv8 bounding boxes are the primary output.\n",
        "\n",
        "Conclusion:\n",
        "  SAM is valuable for annotation quality checks and visualisation,\n",
        "  but bounding-box detection is sufficient for the enforcement pipeline.\n",
        "\"\"\"\n",
        "\n",
        "print(sam_notes)\n",
        "with open('/content/sam_notes.txt', 'w') as f:\n",
        "    f.write(sam_notes)\n",
        "print(\"Saved: /content/sam_notes.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7-md",
      "metadata": {
        "id": "cell-7-md"
      },
      "source": [
        "## Cell 7 — Package Evidence for GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {
        "id": "cell-7"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/evidence_package', exist_ok=True)\n",
        "\n",
        "for fp in [\n",
        "    '/content/validation_predictions_grid.png',\n",
        "    '/content/new_image_predictions_grid.png',\n",
        "    '/content/sam_notes.txt',\n",
        "]:\n",
        "    if os.path.exists(fp):\n",
        "        shutil.copy(fp, '/content/evidence_package/')\n",
        "        print(f\"Copied: {os.path.basename(fp)}\")\n",
        "\n",
        "shutil.make_archive('/content/evidence_package', 'zip', '/content/evidence_package')\n",
        "print(\"\\nevidence_package.zip ready.\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('/content/evidence_package.zip')\n",
        "except ImportError:\n",
        "    print(\"(Not in Colab — download manually)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "footer",
      "metadata": {
        "id": "footer"
      },
      "source": [
        "---\n",
        "## What to do with these outputs\n",
        "\n",
        "1. Unzip `evidence_package.zip` → commit to `/results/evidence/` in the GitHub repo.\n",
        "2. Update `README.md` with real metrics from `01_Training.ipynb` Cell 6.\n",
        "3. Update `docs/error_analysis.md` with specific failure examples from the prediction grids.\n",
        "\n",
        "---\n",
        "*MAICEN 1125 M4 U3 FMP — February 2026*"
      ]
    }
  ]
}